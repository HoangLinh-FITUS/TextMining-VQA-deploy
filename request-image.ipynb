{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10501314,"sourceType":"datasetVersion","datasetId":6501740}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport json\nimport logging\nimport requests\nfrom urllib.parse import urlparse\nimport mimetypes","metadata":{"execution":{"iopub.status.busy":"2025-01-18T01:40:42.767398Z","iopub.execute_input":"2025-01-18T01:40:42.767844Z","iopub.status.idle":"2025-01-18T01:40:42.920670Z","shell.execute_reply.started":"2025-01-18T01:40:42.767811Z","shell.execute_reply":"2025-01-18T01:40:42.919456Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nfrom collections import defaultdict\nimport shutil\nimport numpy as np\nimport sqlite3\nimport pickle\nfrom scipy.spatial.distance import cosine\nfrom transformers import ViTFeatureExtractor, ViTModel\nimport torch","metadata":{"execution":{"iopub.status.busy":"2025-01-18T01:40:42.922159Z","iopub.execute_input":"2025-01-18T01:40:42.922513Z","iopub.status.idle":"2025-01-18T01:41:11.667362Z","shell.execute_reply.started":"2025-01-18T01:40:42.922482Z","shell.execute_reply":"2025-01-18T01:41:11.666093Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\nvit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")","metadata":{"execution":{"iopub.status.busy":"2025-01-18T01:41:11.668576Z","iopub.execute_input":"2025-01-18T01:41:11.669409Z","iopub.status.idle":"2025-01-18T01:41:14.233664Z","shell.execute_reply.started":"2025-01-18T01:41:11.669367Z","shell.execute_reply":"2025-01-18T01:41:14.232068Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"logging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler(\"image_fetch.log\"),  \n        logging.StreamHandler()               \n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2025-01-18T01:41:14.236931Z","iopub.execute_input":"2025-01-18T01:41:14.237264Z","iopub.status.idle":"2025-01-18T01:41:14.242780Z","shell.execute_reply.started":"2025-01-18T01:41:14.237235Z","shell.execute_reply":"2025-01-18T01:41:14.241327Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"GI_API_KEY = os.getenv('API_KEY', 'AIzaSyA43pbijmUNCtMNgSopT7VOimtgERBRXKU')\nGI_SEARCH_ENGINE_ID = os.getenv('SEARCH_ENGINE_ID', 'b6f2650fd0921483a')","metadata":{"execution":{"iopub.status.busy":"2025-01-18T01:41:14.248811Z","iopub.execute_input":"2025-01-18T01:41:14.249111Z","iopub.status.idle":"2025-01-18T01:41:14.275451Z","shell.execute_reply.started":"2025-01-18T01:41:14.249086Z","shell.execute_reply":"2025-01-18T01:41:14.274191Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"PEXELS_API_KEY = os.getenv('API_KEY', 'yxshO7kOwkkbsGf2TmXkfq2MqWaMYjdaVOja0elnSPBXPgBL645wyYhs')","metadata":{"execution":{"iopub.status.busy":"2025-01-18T01:41:14.276468Z","iopub.execute_input":"2025-01-18T01:41:14.276832Z","iopub.status.idle":"2025-01-18T01:41:14.293888Z","shell.execute_reply.started":"2025-01-18T01:41:14.276788Z","shell.execute_reply":"2025-01-18T01:41:14.292688Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def init_database(db_path=\"image_embeddings.db\"):\n    \"\"\"\n    Initialize a database at the given path, creating a table if it doesn't exist.\n\n    Args:\n        db_path (str): Path to the database file. Defaults to \"image_embeddings.db\".\n\n    Returns:\n        sqlite3.Connection: The established connection to the database.\n    \"\"\"\n\n    conn = sqlite3.connect(db_path)\n    cursor = conn.cursor()\n    cursor.execute(\"\"\"\n        CREATE TABLE IF NOT EXISTS embeddings (\n            id INTEGER PRIMARY KEY,\n            url TEXT UNIQUE,\n            embedding BLOB\n        )\n    \"\"\")\n    conn.commit()\n    return conn\n\ndef copy_existing_data(input_folder, output_folder, db_file):\n    \"\"\"Copy existing images and database to a writable output folder.\n\n    Args:\n        \n    \n    \"\"\"\n    \"\"\"\n    if os.path.exists(input_folder):\n        shutil.copytree(input_folder, output_folder, dirs_exist_ok=True)\n    db_input = os.path.join(input_folder, db_file)\n    db_output = os.path.join(output_folder, db_file)\n    if os.path.exists(db_input):\n        shutil.copy(db_input, db_output)\n    return db_output\n    \"\"\"\n    \n    os.makedirs(output_folder, exist_ok=True)\n    db_input = os.path.join(input_folder, db_file)\n    db_output = os.path.join(output_folder, db_file)\n    if os.path.exists(db_input):\n        shutil.copy(db_input, db_output)\n    return db_output\n\ndef save_embedding_to_db(conn, url, embedding):\n    \"\"\"Save an image embedding to the database.\n\n    Args:\n        conn (sqlite3.Connection): Connection to the database.\n        url (str): URL of the image.\n        embedding (numpy.ndarray): The image embedding to save.\n    \"\"\"\n    cursor = conn.cursor()\n    embedding_blob = pickle.dumps(embedding)  \n    try:\n        cursor.execute(\"INSERT INTO embeddings (url, embedding) VALUES (?, ?)\", (url, embedding_blob))\n        conn.commit()\n    except sqlite3.IntegrityError:\n        logging.info(f\"URL already exists in the database: {url}\")\n\ndef is_similar_to_existing(conn, new_embedding, threshold=0.3):\n    \"\"\"\n    Check if the given embedding is similar to any existing embedding in the database.\n    \n    Args:\n        conn (sqlite3.Connection): Connection to the database.\n        new_embedding (numpy.ndarray): The embedding to check.\n        threshold (float, optional): The maximum cosine similarity between the new embedding and an existing one.\n            Defaults to 0.1.\n    \n    Returns:\n        bool: True if the new embedding is similar to an existing one, False otherwise.\n    \"\"\"\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT embedding FROM embeddings\")\n    for row in cursor.fetchall():\n        existing_embedding = pickle.loads(row[0])  \n        similarity = 1 - cosine(new_embedding, existing_embedding)\n        if similarity > (1 - threshold):  \n            return True\n    return False\n\ndef get_image_embedding(image_path):\n    \"\"\"\n    Generate an embedding for an image using a Vision Transformer (ViT).\n\n    Args:\n        image_path (str): Path to the image file for which the embedding is to be generated.\n\n    Returns:\n        numpy.ndarray: A 1D array representing the image embedding generated by the ViT model.\n    \"\"\"\n\n    # Load and preprocess the image\n    image = Image.open(image_path).convert(\"RGB\")\n    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n\n    # Get the output embeddings\n    with torch.no_grad():\n        outputs = vit_model(**inputs)\n        embedding = outputs.last_hidden_state[:, 0, :]  # [CLS] token embedding\n\n    # Convert to numpy array\n    return embedding.squeeze().numpy()\n\ndef load_page_state(state_file=\"page_state.json\"):\n    \"\"\"\n    Load the page state from a file to track which pages have been crawled.\n\n    Args:\n        state_file (str): Path to the state file. Defaults to \"page_state.json\".\n\n    Returns:\n        dict: A dictionary containing the last fetched page number for each category.\n    \"\"\"\n    if os.path.exists(state_file):\n        with open(state_file, \"r\") as file:\n            return json.load(file)\n    return {}\n\ndef save_page_state(page_state, state_file=\"page_state.json\"):\n    \"\"\"\n    Save the page state to a file to track which pages have been crawled.\n\n    Args:\n        page_state (dict): A dictionary containing the last fetched page number for each category.\n        state_file (str): Path to the state file. Defaults to \"page_state.json\".\n    \"\"\"\n    with open(state_file, \"w\") as file:\n        json.dump(page_state, file)\n\ndef fetch_images_from_google_image(category, num_results, state_file=\"page_state.json\", api_key=GI_API_KEY, search_engine_id=GI_SEARCH_ENGINE_ID):\n    \"\"\"\n    Fetch image URLs for a given category using the Google Custom Search API, starting from the last saved page state.\n\n    Args:\n        category (str): The search category or query term.\n        num_results (int): The total number of image URLs to fetch.\n        state_file (str, optional): Path to the state file.\n        api_key (str, optional): The API key for Google Custom Search.\n        search_engine_id (str, optional): The search engine ID for Google Custom Search.\n\n    Returns:\n        list[str]: A list of image URLs fetched for the given category.\n    \"\"\"\n    page_state = load_page_state(state_file)\n    start = page_state.get(category, 1) \n\n    url = \"https://www.googleapis.com/customsearch/v1\"\n    image_urls = []\n\n    while len(image_urls) < num_results:\n        params = {\n            'key': api_key,\n            'cx': search_engine_id,\n            'q': category,\n            'searchType': 'image',\n            'num': min(10, num_results - len(image_urls)),\n            'start': start,\n        }\n        response = requests.get(url, params=params)\n        response.raise_for_status()\n        data = response.json()\n        items = data.get('items', [])\n        if not items:\n            break\n        image_urls.extend([item['link'] for item in items])\n        start += len(items)\n\n    # Update and save page state\n    page_state[category] = start\n    save_page_state(page_state, state_file)\n\n    return image_urls[:num_results]\n\ndef fetch_images_from_pexels(category, num_results, state_file=\"pexels_page_state.json\", api_key=PEXELS_API_KEY):\n    \"\"\"\n    Fetch image URLs for a given category using the Pexels API, starting from the last saved page state.\n\n    Args:\n        category (str): The search category or query term.\n        num_results (int): The total number of image URLs to fetch.\n        state_file (str, optional): Path to the state file. Defaults to \"pexels_page_state.json\".\n        api_key (str, optional): The API key for Pexels API.\n\n    Returns:\n        list[str]: A list of image URLs fetched for the given category.\n    \"\"\"\n    headers = {\"Authorization\": api_key}\n    base_url = \"https://api.pexels.com/v1/search\"\n\n    # Load page state\n    if os.path.exists(state_file):\n        with open(state_file, \"r\") as file:\n            page_state = json.load(file)\n    else:\n        page_state = {}\n\n    page = page_state.get(category, 1)\n    image_urls = []\n\n    while len(image_urls) < num_results:\n        params = {\n            \"query\": category,\n            \"per_page\": min(80, num_results - len(image_urls)), \n            \"page\": page,\n        }\n        response = requests.get(base_url, headers=headers, params=params)\n        response.raise_for_status()\n        data = response.json()\n\n        photos = data.get(\"photos\", [])\n        if not photos: \n            break\n\n        # Collect image URLs\n        image_urls.extend([photo[\"src\"][\"original\"] for photo in photos])\n        page += 1  # Move to the next page\n\n    # Save the updated page state\n    page_state[category] = page\n    with open(state_file, \"w\") as file:\n        json.dump(page_state, file)\n\n    return image_urls[:num_results]\n\ndef fetch_images_from_openverse(category, num_results, state_file=\"openverse_page_state.json\"):\n    \"\"\"\n    Fetch image URLs for a given category using the Openverse API.\n\n    Args:\n        category (str): Search category or query term.\n        num_results (int): Total number of image URLs to fetch.\n        state_file (str, optional): Path to the state file. Defaults to \"openverse_page_state.json\".\n\n    Returns:\n        list[str]: List of image URLs fetched for the given category.\n    \"\"\"\n    base_url = \"https://api.openverse.engineering/v1/images\"\n    page_state = {}\n\n    # Load previous page state if it exists\n    if os.path.exists(state_file):\n        with open(state_file, \"r\") as file:\n            page_state = json.load(file)\n\n    page = page_state.get(category, 1)\n    image_urls = []\n\n    while len(image_urls) < num_results:\n        params = {\n            \"q\": category,\n            \"page\": page,\n            \"page_size\": min(100, num_results - len(image_urls)),\n            \"license\": \"cc0,by\",\n        }\n\n        try:\n            response = requests.get(base_url, params=params)\n            response.raise_for_status()\n            data = response.json()\n\n            results = data.get(\"results\", [])\n            if not results:\n                break\n\n            image_urls.extend([item[\"url\"] for item in results if \"url\" in item])\n            page += 1\n\n        except Exception as e:\n            logging.error(f\"Error fetching images from Openverse: {e}\")\n            break\n\n    # Save updated page state\n    page_state[category] = page\n    with open(state_file, \"w\") as file:\n        json.dump(page_state, file)\n\n    return image_urls[:num_results]\n    \ndef download_images_with_deduplication(urls, folder, db_path=\"image_embeddings.db\"):\n    \"\"\"\n    Downloads images from a list of URLs, checks for duplicates using embeddings, \n    and saves unique images to the specified folder.\n\n    Args:\n        urls (list[str]): List of image URLs to download.\n        folder (str): Folder where images will be saved.\n        db_path (str, optional): Path to the SQLite database for storing and checking image embeddings. Defaults to \"image_embeddings.db\".\n\n    The function creates the folder if it does not exist, downloads each image, generates\n    an embedding, and checks for duplicates against existing embeddings in the database. \n    If an image is not similar to existing ones, it is saved to the folder, and its \n    embedding is saved to the database. Logs info messages for successful downloads and \n    duplicates skipped, and error messages for download failures.\n    \"\"\"\n    os.makedirs(folder, exist_ok=True)\n    conn = init_database(db_path)\n\n    for url in urls:\n        try:\n            response = requests.get(url, stream=True, allow_redirects=True)\n            response.raise_for_status()\n\n            # Save image temporarily for embedding\n            temp_image_path = os.path.join(folder, \"temp.jpg\")\n            with open(temp_image_path, 'wb') as file:\n                file.write(response.content)\n\n            # Generate embedding for the image\n            embedding = get_image_embedding(temp_image_path)\n\n            # Check for similarity\n            if is_similar_to_existing(conn, embedding):\n                logging.info(f\"Duplicate image skipped: {url}\")\n                os.remove(temp_image_path)\n            else:\n                # Save the image and its embedding\n                parsed_url = urlparse(url)\n                file_name = os.path.basename(parsed_url.path)\n                if not os.path.splitext(file_name)[1]:\n                    content_type = response.headers.get('Content-Type', '')\n                    ext = mimetypes.guess_extension(content_type.split(';')[0]) if content_type else '.jpg'\n                    file_name += ext\n                image_path = os.path.join(folder, file_name)\n                os.rename(temp_image_path, image_path)\n                save_embedding_to_db(conn, url, embedding)\n                logging.info(f\"Downloaded: {image_path}\")\n        except Exception as e:\n            logging.error(f\"Failed to download {url}: {e}\")\n\ndef fetch_and_save_images(categories, num_results_per_category, \n                          base_folder=\"images\", db_path=\"image_embeddings.db\", state_file=\"page_state.json\", type=None):\n    \"\"\"\n    Fetches image URLs for each category, downloads the images with deduplication, \n    and saves them into a structured folder hierarchy while keeping track of crawled pages.\n\n    Args:\n        categories (list[str]): List of categories to fetch images for.\n        num_results_per_category (int): Number of image results to fetch per category.\n        base_folder (str, optional): Base folder where images will be saved. Defaults to \"images\".\n        db_path (str, optional): Path to the SQLite database for storing image embeddings. Defaults to \"image_embeddings.db\".\n        state_file (str, optional): Path to the state file. Defaults to \"page_state.json\".\n        type (str, optional): Type of image source (\"Google Image\", \"Pexels\", or \"Openverse\"). \n    \"\"\"\n    # Create the base folder if it does not exist\n    os.makedirs(base_folder, exist_ok=True)\n    \n    # Loop through each category\n    for category in categories:\n        # Create category-specific folder\n        category_folder = os.path.join(base_folder, category)\n        os.makedirs(category_folder, exist_ok=True)\n\n        # Fetch image URLs based on the selected source type\n        if type == 'Google Image':\n            # Fetch URLs using Google Custom Search API\n            fetched_urls = fetch_images_from_google_image(category, num_results_per_category, state_file=state_file)\n            logging.info(f\"Fetched {len(fetched_urls)} URLs from Google Image for category '{category}'.\")\n\n        elif type == 'Pexels':\n            # Fetch URLs using Pexels API\n            fetched_urls = fetch_images_from_pexels(category, num_results_per_category, state_file=state_file)\n            logging.info(f\"Fetched {len(fetched_urls)} URLs from Pexels for category '{category}'.\")\n\n        elif type == 'Openverse':\n            fetched_urls = fetch_images_from_openverse(category, num_results_per_category, state_file=state_file)\n            logging.info(f\"Fetched {len(fetched_urls)} URLs from Openverse for category '{category}'.\")\n\n        else:\n            # Log an error or return if the type is not recognized\n            logging.error(f\"Unrecognized image source type: {type}. Please specify 'Google Image', 'Pexels', or 'Openverse'.\")\n            return\n\n        # Download and save images, avoiding duplicates\n        download_images_with_deduplication(fetched_urls, category_folder, db_path)\n","metadata":{"execution":{"iopub.status.busy":"2025-01-18T01:41:14.294930Z","iopub.execute_input":"2025-01-18T01:41:14.295217Z","iopub.status.idle":"2025-01-18T01:41:14.324025Z","shell.execute_reply.started":"2025-01-18T01:41:14.295194Z","shell.execute_reply":"2025-01-18T01:41:14.322789Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categories = [\n    # Kitchen\n    \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\",\n\n    # Indoor\n    \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\",\n    \n    # Vehicle\n    \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n\n    # Animal\n    \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n]","metadata":{"execution":{"iopub.status.busy":"2025-01-18T01:41:14.325217Z","iopub.execute_input":"2025-01-18T01:41:14.325600Z","iopub.status.idle":"2025-01-18T01:41:14.347939Z","shell.execute_reply.started":"2025-01-18T01:41:14.325568Z","shell.execute_reply":"2025-01-18T01:41:14.346848Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def daily_run():\n    input_folder = \"/kaggle/input/18012025-vqa\"\n    image_input_folder = \"/kaggle/input/18012025-vqa/images\"\n    output_folder = \"/kaggle/working\"\n    image_output_folder = \"/kaggle/working/images\"\n    \n    db_file = \"image_embeddings.db\"\n\n    num_results_per_category = 600\n    gi_state_file=\"page_state_gi.json\"\n    pexels_state_file=\"page_state_pexels.json\"\n    \n    # Types\n    p = 'Pexels'\n    gi = 'Google Image'\n    o = 'Openverse'\n\n    db_path = copy_existing_data(input_folder, output_folder, db_file)\n    \n    conn = init_database(db_path)\n\n    fetch_and_save_images(categories=categories,\n                      num_results_per_category=num_results_per_category,\n                      base_folder=image_output_folder,\n                      db_path=db_path,\n                      state_file=pexels_state_file,type=o)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T01:41:14.349069Z","iopub.execute_input":"2025-01-18T01:41:14.349449Z","iopub.status.idle":"2025-01-18T01:41:14.367062Z","shell.execute_reply.started":"2025-01-18T01:41:14.349411Z","shell.execute_reply":"2025-01-18T01:41:14.365931Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def first_run():\n    num_results_per_category = 500\n    db_path=\"image_embeddings.db\"\n    gi_state_file=\"page_state_gi.json\"\n    pexels_state_file=\"page_state_pexels.json\"\n    base_folder=\"images\"\n    \n    # Types\n    p = 'Pexels'\n    gi = 'Google Image'\n\n    fetch_and_save_images(categories=categories,\n                      num_results_per_category=num_results_per_category,\n                      base_folder=base_folder,\n                      db_path=db_path,\n                      state_file=pexels_state_file,type=p)","metadata":{"execution":{"iopub.status.busy":"2025-01-18T01:41:14.368202Z","iopub.execute_input":"2025-01-18T01:41:14.368582Z","iopub.status.idle":"2025-01-18T01:41:14.389978Z","shell.execute_reply.started":"2025-01-18T01:41:14.368547Z","shell.execute_reply":"2025-01-18T01:41:14.388659Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# first_run()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T01:41:14.390944Z","iopub.execute_input":"2025-01-18T01:41:14.391260Z","iopub.status.idle":"2025-01-18T01:41:14.406259Z","shell.execute_reply.started":"2025-01-18T01:41:14.391234Z","shell.execute_reply":"2025-01-18T01:41:14.405088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"daily_run()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T01:41:14.408893Z","iopub.execute_input":"2025-01-18T01:41:14.409205Z","iopub.status.idle":"2025-01-18T02:21:12.956103Z","shell.execute_reply.started":"2025-01-18T01:41:14.409181Z","shell.execute_reply":"2025-01-18T02:21:12.954098Z"}},"outputs":[],"execution_count":null}]}